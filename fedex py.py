# -*- coding: utf-8 -*-
"""fedex.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yn96ujLKj8Df9rzyXjQH-LuQxw2LwSRQ
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt

df=pd.read_csv("/content/fedex.csv")

df

df.head()

df.shape

df.drop_duplicates()

df.count()

df.info()

"""# feature engineering"""

df.shape

df.isna().sum()

"""## Replacing nun with mean,mode values bold text"""

df.Shipment_Delay.fillna(df.Shipment_Delay.mean(), inplace=True)

df.Actual_Shipment_Time.fillna(df.Actual_Shipment_Time.mean(), inplace=True)

df.Delivery_Status.fillna(df.Delivery_Status.mode()[0], inplace=True)

df.Distance.fillna(df.Distance.mean(), inplace=True)

df['Source'].fillna(df['Source'].mode()[0], inplace=True)

df['Destination'].fillna(df['Destination'].mode()[0], inplace=True)

df['Carrier_Name'].fillna(df['Carrier_Name'].mode()[0], inplace=True)

df.Planned_TimeofTravel.fillna(df.Planned_TimeofTravel.mean(), inplace=True)

df['Carrier_Num'].fillna(df['Carrier_Num'].mode()[0], inplace=True)

df.Planned_Delivery_Time.fillna(df.Planned_Delivery_Time.mean(), inplace=True)

df.Planned_Shipment_Time.fillna(df.Planned_Shipment_Time.mean(), inplace=True)

import seaborn as sns

df.isna().sum()

"""## [counting the unique values in delivery **status**](https://) bold text

```
# This is formatted as code
```


"""

df["Delivery_Status"].value_counts()

df.tail()

sns.countplot(df['Delivery_Status'])
plt.xlabel('Delivery Status')
plt.ylabel('Shipment Delay')

pip install feature_engine

df.head()

df.columns

df=df.iloc[:,[0,1,2,3,4,5,6,8,9,10,13,14,7,11,12]]



"""## [If we have outliers we compressed by winsorizer](https://)"""

plt.boxplot(df['Distance'])

IQR = df['Distance'].quantile(0.75) - df['Distance'].quantile(0.25)
lower_limit = df['Distance'].quantile(0.25) - (IQR * 1.5)
upper_limit = df['Distance'].quantile(0.75) + (IQR * 1.5)

from feature_engine.outliers import Winsorizer


winsor = Winsorizer(capping_method='iqr',
                          tail='both', 
                          fold=1.5,
                          variables=['Distance'])

df_t = winsor.fit_transform(df[['Distance']])

df['Distance']=df_t

plt.boxplot(df['Distance'])

plt.boxplot(df['Actual_Shipment_Time'])

plt.boxplot(df['Planned_TimeofTravel'])

IQR = df['Planned_TimeofTravel'].quantile(0.75) - df['Planned_TimeofTravel'].quantile(0.25)
lower_limit = df['Planned_TimeofTravel'].quantile(0.25) - (IQR * 1.5)
upper_limit = df['Planned_TimeofTravel'].quantile(0.75) + (IQR * 1.5)

winsor = Winsorizer(capping_method='iqr',
                          tail='both', 
                          fold=1.5,
                          variables=['Planned_TimeofTravel'])

df_t = winsor.fit_transform(df[['Planned_TimeofTravel']])

df['Planned_TimeofTravel']=df_t

plt.boxplot(df['Planned_TimeofTravel'])

plt.boxplot(df.Planned_TimeofTravel)

plt.boxplot(df['Planned_TimeofTravel'])

plt.boxplot(df['Shipment_Delay'])

IQR = df['Shipment_Delay'].quantile(0.75) - df['Shipment_Delay'].quantile(0.25)
lower_limit = df['Shipment_Delay'].quantile(0.25) - (IQR * 1.5)
upper_limit = df['Shipment_Delay'].quantile(0.75) + (IQR * 1.5)

winsor = Winsorizer(capping_method='iqr',
                          tail='both', 
                          fold=1.5,
                          variables=['Shipment_Delay'])
df_t = winsor.fit_transform(df[['Shipment_Delay']])
df['Shipment_Delay']=df_t
plt.boxplot(df['Shipment_Delay'])

df.columns

df.head()



df1=pd.DataFrame()

df1

from sklearn import preprocessing
le=preprocessing.LabelEncoder()

df1['Destination']=le.fit_transform(df.Destination)

df1['Carrier_Name']=le.fit_transform(df.Carrier_Name)

df1['Source']=le.fit_transform(df.Source)

df1

df2=df.iloc[:,:12]

df2

fedex_=df1.add(df2,fill_value=0)

fedex_

sns.heatmap(df.corr(), annot=True,cmap ='RdYlGn')
plt.title('fedex_')
plt.rcParams['figure.figsize']=(10,10)

predictors=fedex_.iloc[:,:14]

target=fedex_["Delivery_Status"]

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

scaler.fit_transform(predictors)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train ,y_test = train_test_split(predictors,target,test_size=0.3)

from sklearn.tree import DecisionTreeRegressor

from sklearn import tree

regtree=tree.DecisionTreeRegressor(max_depth=5)

from sklearn.tree import DecisionTreeClassifier as DT

help(DT)
model = DT(min_samples_split = 5)

model.fit(X_train, y_train)

test_predictors=model.predict(X_test)

pd.crosstab(test_predictors,y_test,rownames=['actual'],colnames=['predic'])

np.mean(test_predictors==y_test)

train_predictors=model.predict(X_train)

pd.crosstab(train_predictors,y_train,rownames=['actual'],colnames=['predic'])

np.mean(train_predictors==y_train)

"""# ***GridsearchCV***"""

from sklearn.model_selection import GridSearchCV

model = DT(criterion = 'entropy')

param_grid = {'min_samples_leaf': [1, 5, 10, 20],
              'max_depth': [2, 4, 6, 8, 10],
              'max_features': ['sqrt']}


grid_search = GridSearchCV(estimator = model, param_grid = param_grid, 
                                scoring = 'accuracy', n_jobs = -1, cv = 5, 
                                refit=True, return_train_score=True)

grid_search.fit(X_train, y_train)

grid_search.best_params_

cv_dt_clf_grid = grid_search.best_estimator_

from sklearn.metrics import accuracy_score, confusion_matrix

confusion_matrix(y_test, cv_dt_clf_grid.predict(X_test))
accuracy_score(y_test, cv_dt_clf_grid.predict(X_test))

# Evaluation on Training Data
confusion_matrix(y_train, cv_dt_clf_grid.predict(X_train))
accuracy_score(y_train, cv_dt_clf_grid.predict(X_train))

"""# network analytics """

import networkx as nx

df.head()



scaler.fit_transform(df.iloc[:,:11])



fedex

fedex=df.iloc[:100,:]

g=nx.Graph()

g=nx.from_pandas_edgelist(fedex,source="Source",target="Destination")

print(nx.info(g))

a=nx.degree_centrality(g)

pos=nx.spring_layout(g,k=0.15)
nx.draw_networkx(g,pos,node_color="red",node_size=23)

##closeness centrality
b=nx.closeness_centrality(g)

b

#b/w
c=nx.betweenness_centrality(g)

c

###eigonvector
d=nx.eigenvector_centrality(g)

d

##cluster
e=nx.clustering(g)

e

##avg
f=nx.average_clustering(g)

f